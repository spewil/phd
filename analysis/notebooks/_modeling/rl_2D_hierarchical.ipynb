{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax  # Autodiff, easy batching of functions\n",
    "import jax.numpy as jnp  # Like numpy but written to run fast on GPU\n",
    "import numpy as np\n",
    "import distrax  # Tensorflow probability for Jax\n",
    "import haiku as hk  # Used for making neural nets\n",
    "import tqdm  # Used for reporting training progress\n",
    "import chex  # Used for checking dimensions, useful for debugging\n",
    "from jax.scipy.linalg import cholesky  # Need to structure covariance appropriately for learning\n",
    "from matplotlib import pyplot as plt\n",
    "from functools import partial\n",
    "from matplotlib import pyplot as plt\n",
    "import optax  # Used for optimization using SGD, Adam etc\n",
    "\n",
    "# plt.style.use('seaborn-v0_8-deep')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### notes\n",
    "\n",
    "- why does the fit gaussian have this shape not matter where the target is?\n",
    "- we can play with the $\\beta$ for the KL penalty, if this goes above ~200 we see a pull from the prior\n",
    "- the prior log prob seems to make no difference to the solution\n",
    "- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### policy gradient with KL penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prior is a mixture of $N$ components, and the policy is a Gaussian:\n",
    "\n",
    "\\begin{align}\n",
    "    \\pi_0(x) \\propto p(x|\\mathbf{\\mu}, \\mathbf{\\Sigma}) &= \\sum_i^N{w_i\\mathcal{N}(\\mu_i, \\Sigma_i)} \\\\ \n",
    "    \\sum_i{w_i} &= 1 \\\\\n",
    "    \\pi(x) &\\propto p(x|\\mu_p, \\Sigma_p) = \\mathcal{N}(\\mu_p, \\Sigma_p)\n",
    "\\end{align}\n",
    "\n",
    "Fit GMM to data to serve as the prior, $x_prior$.\n",
    "\n",
    "Train the policy distribution using reward:\n",
    "\n",
    "\\begin{align} \n",
    "    r(x,t) &= -|t - x|^2\n",
    "\\end{align}\n",
    "<!-- return -jnp.sum(jnp.subtract(a, target_params[\"loc\"])**2,axis=1) -->\n",
    "\n",
    "given $t$ the target\n",
    "\n",
    "and loss function to minimize:\n",
    "\n",
    "\\begin{align}\n",
    "   \\mathcal{L}(a,r,p_{policy},p_{prior}) &= -\\sum_k{r_k(\\log{p(a_k|p_{policy})} + \\log{p(a_k|p_{prior})})} \\\\\n",
    "   \\\\ &+ \\beta * \\mathcal{KL}(p_{prior},p_{policy})\n",
    "\\end{align}\n",
    "<!-- return -(rewards * (log_probs)).sum() + alpha*penalty -->\n",
    "\n",
    "where the KL penalty is sum over prior components:\n",
    "\n",
    "$$\n",
    "    \\mathcal{KL}(p_{prior},p_{policy}) = \\sum_k{w_k}\\mathcal{D}_{KL}(\\mathcal{N}(\\mu_p,\\Sigma_p),\\mathcal{N}(\\mu_k,\\Sigma_k))\n",
    "$$\n",
    "<!-- penalty += weight*component.kl_divergence(dist_model) -->\n",
    "\n",
    "gradient update: \n",
    "\n",
    "$$\n",
    "\\theta_{policy}' = \\theta_{policy} + \\nabla_{\\theta}(\\mathcal{L})\n",
    "$$\n",
    "<!-- Probably a more accurate line here -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTION_DIM = 2\n",
    "batch_size = 500\n",
    "key = jax.random.PRNGKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_cov(sq_mat):\n",
    "    return jnp.dot(sq_mat.T, sq_mat)\n",
    "\n",
    "\n",
    "@jax.jit\n",
    "def normal_policy_log_prob(params, actions, prior_params):\n",
    "  chex.assert_shape(actions, (None,ACTION_DIM))\n",
    "\n",
    "  dist_prior = distrax.MultivariateNormalTri(\n",
    "        loc=jnp.array(prior_params['loc']), scale_tri=(prior_params['scale'])\n",
    "        )\n",
    "\n",
    "  dist_model = distrax.MultivariateNormalTri(\n",
    "      loc=jnp.array(params['loc']), scale_tri=(params['scale'])\n",
    "      )\n",
    "\n",
    "  log_probs_prior = dist_prior.log_prob(actions)\n",
    "  log_probs_model = dist_model.log_prob(actions)\n",
    "  chex.assert_shape(log_probs_prior, (actions.shape[0],))\n",
    "  chex.assert_shape(log_probs_model, (actions.shape[0],))\n",
    "\n",
    "  return log_probs_model + log_probs_prior\n",
    "\n",
    "@jax.jit\n",
    "def mixture_policy_log_prob(params, actions, prior_params):\n",
    "  chex.assert_shape(actions, (None,ACTION_DIM))\n",
    "\n",
    "  dist_prior = distrax.MixtureSameFamily(\n",
    "        mixture_distribution = distrax.Categorical(\n",
    "          probs=(prior_params[\"mixture_probs\"])),\n",
    "        components_distribution = distrax.MultivariateNormalTri(\n",
    "          loc=prior_params[\"means\"],scale_tri=(prior_params[\"scales\"])),\n",
    "        )\n",
    "\n",
    "  dist_model = distrax.MultivariateNormalTri(\n",
    "      loc=jnp.array(params['loc']), scale_tri=(params['scale'])\n",
    "      )\n",
    "\n",
    "  log_probs_prior = dist_prior.log_prob(actions)\n",
    "  log_probs_model = dist_model.log_prob(actions)\n",
    "  chex.assert_shape(log_probs_prior, (actions.shape[0],))\n",
    "  chex.assert_shape(log_probs_model, (actions.shape[0],))\n",
    "\n",
    "  return log_probs_model + log_probs_prior\n",
    "\n",
    "@partial(jax.jit, static_argnums=(2,))\n",
    "def policy_sample(rng, params, num_samples):\n",
    "  \"\"\"See policy log prob.\"\"\"\n",
    "  eps = 1e-4\n",
    "  samples = distrax.MultivariateNormalTri(\n",
    "      loc=params['loc'],\n",
    "      scale_tri=(params['scale'])\n",
    "      ).sample(seed=rng, sample_shape=(num_samples,))\n",
    "  chex.assert_shape(samples, (num_samples, ACTION_DIM))\n",
    "  return samples\n",
    "\n",
    "@partial(jax.jit, static_argnums=(3,))\n",
    "def policy_sample_hierarchical(rng, params, prior_params, num_samples):\n",
    "  \"\"\"See policy log prob.\"\"\"\n",
    "  prior_samples = make_prior_dist(prior_params).sample(seed=rng, sample_shape=(num_samples,))\n",
    "  policy = lambda mean: distrax.MultivariateNormalTri(loc=mean, scale_tri=(params['scale']))\n",
    "  policy_samples = jnp.array([policy(s).sample(seed=key,sample_shape=(1,)).reshape((2)) for s in prior_samples])\n",
    "  chex.assert_shape(policy_samples, (num_samples, ACTION_DIM))\n",
    "  return policy_samples\n",
    "\n",
    "\n",
    "@partial(jax.jit, static_argnums=(2,))\n",
    "def univariate_policy_sample(rng, params, num_samples):\n",
    "  mu = jnp.array(params['loc'])\n",
    "  sigma = (jnp.array(params['scale']))\n",
    "\n",
    "  eps = 1e-4\n",
    "  samples = distrax.Normal(loc=mu, scale=sigma).sample(seed=rng, sample_shape=(num_samples,)).reshape(-1)\n",
    "  chex.assert_shape(samples, (num_samples,))\n",
    "\n",
    "  return samples\n",
    "\n",
    "def kl_penalty(params, prior_params):\n",
    "  dist_prior = distrax.MixtureSameFamily(\n",
    "        mixture_distribution = distrax.Categorical(probs=(prior_params[\"mixture_probs\"])),\n",
    "        components_distribution = distrax.MultivariateNormalTri(loc=prior_params[\"means\"],scale_tri=(prior_params[\"scales\"])),\n",
    "        )\n",
    "\n",
    "  dist_model = distrax.MultivariateNormalTri(\n",
    "      loc=jnp.array(params['loc']), scale_tri=(params['scale'])\n",
    "      )\n",
    "  \n",
    "  penalty = 0\n",
    "  for weight, component in zip(dist_prior.mixture_distribution.probs, dist_prior.components_distribution):\n",
    "    penalty += weight*component.kl_divergence(dist_model)\n",
    "\n",
    "  return penalty\n",
    "\n",
    "def kl_penalty_proper(params, prior_params, n_samples=5000):\n",
    "    dist_prior = distrax.MixtureSameFamily(\n",
    "          mixture_distribution = distrax.Categorical(probs=(prior_params[\"mixture_probs\"])),\n",
    "          components_distribution = distrax.MultivariateNormalTri(loc=prior_params[\"means\"],scale_tri=(prior_params[\"scales\"])),\n",
    "          )\n",
    "    dist_policy = distrax.MultivariateNormalTri(\n",
    "        loc=jnp.array(params['loc']), scale_tri=(params['scale'])\n",
    "        )\n",
    "    \n",
    "    # This is one way!\n",
    "    # # sample from the prior, this is what we're taking the expectation under!\n",
    "    # prior_samples = dist_prior.sample(seed=key, sample_shape=(n_samples,))\n",
    "    # # get log probs under the prior and policy  \n",
    "    # prior_x = dist_prior.log_prob(prior_samples)\n",
    "    # policy_x = dist_policy.log_prob(prior_samples)\n",
    "    # return jnp.mean(prior_x - policy_x)\n",
    "\n",
    "    # This is the other way\n",
    "    # sample from the policy, this is what we're taking the expectation under!\n",
    "    policy_samples = dist_policy.sample(seed=key, sample_shape=(n_samples,))\n",
    "    # get log probs under the prior and policy  \n",
    "    prior_x = dist_prior.log_prob(policy_samples)\n",
    "    policy_x = dist_policy.log_prob(policy_samples)\n",
    "    return jnp.mean(policy_x - prior_x)\n",
    "\n",
    "def loss_fn(params, actions, rewards, prior_params, alpha):\n",
    "  chex.assert_shape(actions, (batch_size,ACTION_DIM))\n",
    "  chex.assert_shape(rewards, (batch_size,))\n",
    "  log_probs = mixture_policy_log_prob(params, actions, prior_params)\n",
    "  # penalty = kl_penalty(params, prior_params)\n",
    "  # penalty = kl_penalty_proper(params, prior_params)\n",
    "  chex.assert_shape(log_probs, (batch_size,))\n",
    "  rewards = jax.lax.stop_gradient(rewards)  # Don't backprop through the reward function\n",
    "  # log probs are always negative! rewards are negated, so we end up with a positive\n",
    "  # KL distance is positive, so we leave this to minimize\n",
    "  # negative the whole thing because we're minimizing this quantity\n",
    "  return (rewards * -log_probs).sum() # + alpha*penalty\n",
    "\n",
    "@jax.jit\n",
    "def get_rewards(a, target_params, key):\n",
    "  # # sample from target distribution, compute distances, sum (effectively averages)\n",
    "  # target_dist = distrax.MultivariateNormalTri(\n",
    "  #     loc=jnp.array(target_params['loc']), scale_tri=(target_params['scale'])\n",
    "  #     )\n",
    "  # target_samples = target_dist.sample(seed=key, sample_shape=(a.shape[0],))\n",
    "  # # maximize the negative of the error (minimize the error)\n",
    "  # return -jnp.sum(jnp.subtract(a, target_samples)**2,axis=1)\n",
    "  # subtract from target distribution mean\n",
    "  return -jnp.sum(jnp.subtract(a, target_params[\"loc\"])**2,axis=1)\n",
    "\n",
    "@jax.jit  # This compiles the function to the GPU\n",
    "def update_fn(params, actions, rewards, opt_state, prior_params, alpha, wlr=1e-4, epsilon=1e-8):\n",
    "  optimizer = optax.adam(wlr)\n",
    "  loss = loss_fn(params, actions, rewards, prior_params, alpha=alpha)\n",
    "  grads = jax.grad(loss_fn)(params, actions, rewards, prior_params, alpha)\n",
    "  updates, opt_state = optimizer.update(grads, opt_state)\n",
    "  params = optax.apply_updates(params, updates)\n",
    "  params['scale'] = jnp.clip(params['scale'], a_min=epsilon)  # Clip for numerical stability\n",
    "  return params, opt_state, loss\n",
    "\n",
    "\n",
    "def setup_params():\n",
    "    mixture_probs = jnp.array([0.1,0.9])\n",
    "    mixture_means = [[10.,25.],[-10., -25.]]\n",
    "    mixture_scales = jnp.linalg.cholesky(jnp.array([[[5.0,0.0],\n",
    "                                                     [0.0,5.0]],\n",
    "                                                    [[5.0,0.0],\n",
    "                                                    [0.0,5.0]]]))\n",
    "    mixture_params = {\n",
    "        \"mixture_probs\" : (mixture_probs),\n",
    "        \"means\" : mixture_means,\n",
    "        \"scales\" : (mixture_scales)\n",
    "    }\n",
    "\n",
    "    starting_mean = jnp.array([10.,-10.])\n",
    "    starting_sigma = 10.0\n",
    "    starting_scale = jnp.linalg.cholesky(jnp.array([[1.0,  0.0],\n",
    "                                                    [0.0,  1.0]]))*starting_sigma\n",
    "    params = {\n",
    "        'loc': starting_mean,\n",
    "        'scale': (starting_scale)\n",
    "        }\n",
    "\n",
    "    target_position = jnp.array([30.0,10.0])\n",
    "    target_scale = jnp.linalg.cholesky(jnp.array([[15.0,  -14.],\n",
    "                                                  [-14.,  15.0]]))\n",
    "    target_params = {\n",
    "        'loc': target_position,\n",
    "        'scale': (target_scale)\n",
    "    }\n",
    "    return mixture_params, params, target_params\n",
    "\n",
    "def plot_samples(dist,num_samples,label,rng):\n",
    "  # split for new samples\n",
    "  key, subkey = jax.random.split(rng)\n",
    "  samples = dist.sample(seed=subkey, sample_shape=(num_samples,)).T\n",
    "  plt.scatter(samples[0],samples[1],label=label)\n",
    "\n",
    "def make_target_dist(target_params):\n",
    "    return  distrax.MultivariateNormalTri(\n",
    "    loc=target_params['loc'],\n",
    "    scale_tri=(target_params['scale']))\n",
    "\n",
    "def make_prior_dist(mixture_params):\n",
    "   return distrax.MixtureSameFamily(\n",
    "    mixture_distribution = distrax.Categorical(probs=(mixture_params[\"mixture_probs\"])),\n",
    "    components_distribution = distrax.MultivariateNormalTri(loc=mixture_params[\"means\"],scale_tri=(mixture_params[\"scales\"])))\n",
    "\n",
    "def make_starting_dist(starting_params):\n",
    "    return distrax.MultivariateNormalTri(\n",
    "    loc=starting_params['loc'],\n",
    "    scale_tri=(starting_params['scale']))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixture_params, params, target_params = setup_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2550/5000 [00:10<00:09, 248.91it/s]"
     ]
    }
   ],
   "source": [
    "num_iter = 5000\n",
    "learning_rate = 1e-2\n",
    "opt_state = optax.adam(learning_rate).init(params)\n",
    "losses = np.zeros(num_iter)\n",
    "rewards = np.zeros(num_iter)\n",
    "params_list = []\n",
    "\n",
    "for t in tqdm.tqdm(range(num_iter)):\n",
    "  key, subkey = jax.random.split(key)\n",
    "  actions_t = policy_sample(rng=subkey, params=params, num_samples=batch_size)\n",
    "  # actions_t = policy_sample_hierarchical(rng=subkey, params=params, prior_params=mixture_params, num_samples=batch_size)\n",
    "  rewards_t = get_rewards(actions_t, target_params, key)\n",
    "  rewards[t] = rewards_t.mean()\n",
    "  params_list.append(params)\n",
    "  params, opt_state, loss_t = update_fn(params, actions_t, rewards_t, opt_state, alpha=0.01, prior_params=mixture_params, wlr=learning_rate)\n",
    "  losses[t] = loss_t\n",
    "  params_list.append(params)\n",
    "means = np.array([[p[\"loc\"][0],p[\"loc\"][1]] for p in params_list]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[228], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(means[\u001b[38;5;241m0\u001b[39m],means[\u001b[38;5;241m1\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(target_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m],target_params[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 15\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mparams_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m0\u001b[39m],params_list[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloc\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m1\u001b[39m],\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg*\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure()\n\u001b[1;32m     18\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(losses,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mk-\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# def plot_2d_dist(dist):\n",
    "#   xl = jnp.linspace(-20,20,100)\n",
    "#   yl = jnp.linspace(-20,20,100)\n",
    "#   x, y = jnp.meshgrid(xl, yl)\n",
    "#   X = jnp.stack([xm.flatten(), ym.flatten()], axis=-1)\n",
    "#   probs = dist.prob(X).reshape((101, 101))\n",
    "#   left,right,bottom,top = xl.min(), xl.max(), yl.min(), yl.max()\n",
    "#   plt.imshow(probs, extent=(left,right,bottom,top), origin=\"lower\")\n",
    "#   _ = plt.gca().set_xticks(xl[::10],labels=np.round(xl[::10]),rotation=45)\n",
    "#   _ = plt.gca().set_yticks(yl[::10],labels=np.round(yl[::10]),rotation=45)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(means[0],means[1],\"k-\")\n",
    "plt.plot(target_params[\"loc\"][0],target_params[\"loc\"][1],\"r*\")\n",
    "plt.plot(params_list[0][\"loc\"][0],params_list[0][\"loc\"][1],\"g*\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(losses,\"k-\")\n",
    "plt.title(\"Loss\")\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot([kl_penalty(p,mixture_params) for p in params_list])\n",
    "# plt.title(\"KL Penalty\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(rewards,\"k-\")\n",
    "plt.title(\"Reward\")\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.gca().set_aspect(\"auto\")\n",
    "\n",
    "plot_samples(make_prior_dist(mixture_params),1000,\"Mixture Prior\",rng=key)\n",
    "plot_samples(make_target_dist(target_params),1000,\"Target\",rng=key)\n",
    "plot_samples(make_starting_dist(params_list[0]),1000,\"Starting\",rng=key)\n",
    "plt.plot(target_params[\"loc\"][0],target_params[\"loc\"][1],\"r*\",label=\"Target Mean\")\n",
    "\n",
    "middle_dist = distrax.MultivariateNormalTri(\n",
    "    loc=params_list[500]['loc'],\n",
    "    scale_tri=(params_list[500]['scale']),\n",
    "    )\n",
    "plot_samples(middle_dist,1000,\"Middle\",key)\n",
    "\n",
    "late_dist = distrax.MultivariateNormalTri(\n",
    "    loc=params_list[-100]['loc'],\n",
    "    scale_tri=(params_list[-100]['scale']),\n",
    "    )\n",
    "plot_samples(late_dist,1000,\"Late\",key)\n",
    "\n",
    "fitted_dist = distrax.MultivariateNormalTri(\n",
    "    loc=params['loc'],\n",
    "    scale_tri=(params['scale']),\n",
    "    )\n",
    "plot_samples(fitted_dist,1000,\"Fit\",key)\n",
    "\n",
    "plt.plot([p[\"loc\"][0] for p in params_list],[p[\"loc\"][1] for p in params_list],\"k--\")\n",
    "plt.plot(target_params[\"loc\"][0],target_params[\"loc\"][1],\"r*\",markersize=15)\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
