
@article{bahlNeuralDynamicPoliciesfor2020,
  title = {Neural {{Dynamic Policiesfor End}}-to-{{End Sensorimotor Learning}}},
  author = {Bahl, Shikhar and Mukadam, Mustafa and Gupta, Abhinav and Pathak, Deepak},
  year = {2020},
  pages = {5},
  abstract = {The current dominant paradigm in sensorimotor control, whether imitation or reinforcement learning, is to train policies directly in raw action spaces. This forces the agent to make decisions at each point in training, and limits scalability to complex tasks. In contrast, classical robotics research has exploited dynamical systems as policy representations to learn behaviors via demonstrations. These techniques, however, lack the flexibility provided by deep learning and have remained under-explored in such settings. In this work, we begin to close this gap and embed dynamics structure into deep neural network-based policies by reparameterizing action spaces with differential equations. We propose Neural Dynamic Policies (NDPs) that make predictions in trajectory distribution space as opposed to raw control spaces. The embedded structure allows us to perform end-to-end policy learning in both reinforcement and imitation learning setups. We show that NDPs achieve state-of-the-art performance on many robotic control tasks in simulation, as well as on digit writing using demonstrations.},
  file = {/Users/spencerw/Zotero/storage/HWWCTHLR/Bahl et al_2020_Neural Dynamic Policiesfor End-to-End Sensorimotor Learning.pdf},
  keywords = {_tablet},
  language = {en}
}

@book{Bernstein1967,
  title = {The Coordination and Regulation of Movements},
  author = {Bernstein, N},
  year = {1967},
  publisher = {{Pergamon}},
  address = {{Oxford}},
  keywords = {Animal locomotion}
}

@article{bizziMotorPlanningExecution2020,
  title = {From Motor Planning to Execution: A Sensorimotor Loop Perspective},
  shorttitle = {From Motor Planning to Execution},
  author = {Bizzi, Emilio and Ajemian, Robert},
  year = {2020},
  month = dec,
  volume = {124},
  pages = {1815--1823},
  issn = {0022-3077, 1522-1598},
  doi = {10.1152/jn.00715.2019},
  abstract = {How is an evanescent wish to move translated into a concrete action? This simple question and puzzling miracle remains a focal point of motor systems neuroscience. Where does the difficulty lie? A great deal has been known about biomechanics for quite some time. More recently, there have been significant advances in our understanding of how the spinal system is organized into modules corresponding to spinal synergies, which are fixed patterns of multimuscle recruitment. But much less is known about how the supraspinal system recruits these synergies in the correct spatiotemporal pattern to effectively control movement. We argue that what makes the problem of supraspinal control so difficult is that it emerges as a result of multiple convergent and redundant sensorimotor loops. Because these loops are convergent, multiple modes of information are mixed before being sent to the spinal system; because they are redundant, information is overlapping such that a mechanism must exist to eliminate the redundancy before the signal is sent to the spinal system. Given these complex interactions, simple correlation analyses between movement variables and neural activity are likely to render a confusing and inconsistent picture. Here, we suggest that the perspective of sensorimotor loops might help in achieving a better systems-level understanding. Furthermore, state-of-the-art techniques in neurotechnology, such as optogenetics, appear to be well suited for investigating the problem of motor control at the level of loops.},
  file = {/Users/spencerw/Zotero/storage/KFW88U4M/Bizzi_Ajemian_2020_From motor planning to execution.pdf},
  journal = {Journal of Neurophysiology},
  keywords = {_tablet},
  language = {en},
  number = {6}
}

@article{kimPsychologyReachingAction2021a,
  title = {The {{Psychology}} of {{Reaching}}: {{Action Selection}}, {{Movement Implementation}}, and {{Sensorimotor Learning}}},
  shorttitle = {The {{Psychology}} of {{Reaching}}},
  author = {Kim, Hyosub E. and Avraham, Guy and Ivry, Richard B.},
  year = {2021},
  month = jan,
  volume = {72},
  pages = {61--95},
  issn = {0066-4308, 1545-2085},
  doi = {10.1146/annurev-psych-010419-051053},
  abstract = {The study of motor planning and learning in humans has undergone a dramatic transformation in the 20 years since this journal's last review of this topic. The behavioral analysis of movement, the foundational approach for psychology, has been complemented by ideas from control theory, computer science, statistics, and, most notably, neuroscience. The result of this interdisciplinary approach has been a focus on the computational level of analysis, leading to the development of mechanistic models at the psychological level to explain how humans plan, execute, and consolidate skilled reaching movements. This review emphasizes new perspectives on action selection and motor planning, research that stands in contrast to the previously dominant representation-based perspective of motor programming, as well as an emerging literature highlighting the convergent operation of multiple processes in sensorimotor learning.},
  file = {/Users/spencerw/Zotero/storage/XISGEM2U/Kim et al_2021_The Psychology of Reaching.pdf},
  journal = {Annual Review of Psychology},
  keywords = {_tablet},
  language = {en},
  number = {1}
}

@article{kitanoBiologicalRobustness2004,
  title = {Biological Robustness},
  author = {Kitano, Hiroaki},
  year = {2004},
  month = nov,
  volume = {5},
  pages = {826--837},
  issn = {1471-0056, 1471-0064},
  doi = {10.1038/nrg1471},
  abstract = {Robustness is a ubiquitously observed property of biological systems. It is considered to be a fundamental feature of complex evolvable systems. It is attained by several underlying principles that are universal to both biological organisms and sophisticated engineering systems. Robustness facilitates evolvability and robust traits are often selected by evolution. Such a mutually beneficial process is made possible by specific architectural features observed in robust systems. But there are trade-offs between robustness, fragility, performance and resource demands, which explain system behaviour, including the patterns of failure. Insights into inherent properties of robust systems will provide us with a better understanding of complex diseases and a guiding principle for therapy design.},
  file = {/Users/spencerw/Zotero/storage/R3KH2NCB/Kitano_2004_Biological robustness.pdf},
  journal = {Nature Reviews Genetics},
  keywords = {_tablet},
  language = {en},
  number = {11}
}

@article{McNamee2019,
  title = {Internal {{Models}} in {{Biological Control}}},
  author = {McNamee, Daniel and Wolpert, Daniel M.},
  year = {2019},
  volume = {2},
  pages = {339--364},
  issn = {2573-5144},
  doi = {10.1146/annurev-control-060117-105206},
  abstract = {Rationality principles such as optimal feedback control and Bayesian inference underpin a probabilistic framework that has accounted for a range of empirical phenomena in biological sensorimotor control. To facilitate the optimization of flexible and robust behaviors consistent with these theories, the ability to construct internal models of the motor system and environmental dynamics can be crucial. In the context of this theoretic formalism, we review the computational roles played by such internal models and the neural and behavioral evidence for their implementation in the brain.},
  file = {/Users/spencerw/Zotero/storage/XM5UTV48/McNamee, Wolpert - 2019 - Internal Models in Biological Control.pdf},
  journal = {Annual Review of Control, Robotics, and Autonomous Systems},
  keywords = {â˜…,bayesian inference,feedback control,internal model,optimal,planning,predictive control,state estimation},
  number = {1}
}

@techreport{pirayLinearReinforcementLearning2019a,
  title = {Linear Reinforcement Learning: {{Flexible}} Reuse of Computation in Planning, Grid Fields, and Cognitive Control},
  shorttitle = {Linear Reinforcement Learning},
  author = {Piray, Payam and Daw, Nathaniel D.},
  year = {2019},
  month = nov,
  institution = {{Neuroscience}},
  doi = {10.1101/856849},
  abstract = {It is thought that the brain's judicious allocation and reuse of computation underlies our ability to plan flexibly, but also failures to do so as in habits and compulsion. Yet we lack a complete, realistic account of either. Building on control engineering, we introduce a new model for decision making in the brain that reuses a temporally abstracted map of future events to enable biologically-realistic, flexible choice at the expense of specific, quantifiable biases. It replaces the classic nonlinear, model-based optimization with a linear approximation that softly maximizes around (and is weakly biased toward) a learned default policy. This solution exposes connections between seemingly disparate phenomena across behavioral neuroscience, notably flexible replanning with biases and cognitive control. It also gives new insight into how the brain can represent maps of long-distance contingencies stably and componentially, as in entorhinal response fields, and exploit them to guide choice even under changing goals.},
  file = {/Users/spencerw/Zotero/storage/YCB6GQ3K/Piray_Daw_2019_Linear reinforcement learning.pdf},
  keywords = {_tablet},
  language = {en},
  type = {Preprint}
}


